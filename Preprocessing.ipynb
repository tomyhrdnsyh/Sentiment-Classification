{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00af0589",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ca3be5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af44005",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9451f89",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808b8b7a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(\"assets/nadiem_comment_2.xlsx\", usecols=['content', 'sentiment'])\n",
    "dataset['content'].str.encode('ascii', 'ignore')\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbb6b0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Drop Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb79166",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf50e4b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4264babd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3308c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327bdc83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_unique_character(text):\n",
    "    text = text.replace('\\t', \" \").replace('\\n', \" \").replace(r'\\u', ' ') # remove tab, new line, ans back slice\n",
    "    text = text.encode('ascii', 'replace').decode('ascii') # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split()) # remove mention, link, hashtag\n",
    "    text = text.replace(\"http://\", \" \").replace(\"https://\", \" \") # remove incomplete URL\n",
    "    text = re.sub(r\"\\d+\", \"\", text) #remove number\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) #remove punctuation/tanda baca\n",
    "    text = text.strip() #remove whitespace leading & trailing\n",
    "    text = re.sub('\\s+',' ',text) #remove multiple whitespace into single whitespace\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text) #remove single character\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b70e9b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                           cleansing  \n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['cleansing'] = dataset['content'].apply(remove_unique_character)\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a8a46",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d06f4038",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>paa bales dm pa saya mau nanya soal paket bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                        case_folding  \n",
       "0  paa bales dm pa saya mau nanya soal paket bela...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['case_folding'] = dataset['cleansing'].str.lower()\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9ad8d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5815a55",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>paa bales dm pa saya mau nanya soal paket bela...</td>\n",
       "      <td>[paa, bales, dm, pa, saya, mau, nanya, soal, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                        case_folding  \\\n",
       "0  paa bales dm pa saya mau nanya soal paket bela...   \n",
       "\n",
       "                                        tokenization  \n",
       "0  [paa, bales, dm, pa, saya, mau, nanya, soal, p...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "dataset['tokenization'] = dataset['case_folding'].apply(word_tokenize_wrapper)\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e3c13",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc43f05d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ----------- normalized ------------\n",
    "normalizad_word = pd.read_excel(r\"assets/key_norm.xlsx\")\n",
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in normalizad_word.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1]\n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934a82b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenization</th>\n",
       "      <th>normalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>paa bales dm pa saya mau nanya soal paket bela...</td>\n",
       "      <td>[paa, bales, dm, pa, saya, mau, nanya, soal, p...</td>\n",
       "      <td>[paa, balas, dm, pa, saya, mau, bertanya, soal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak......</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak An...</td>\n",
       "      <td>berikan kesejahteraan buat guru honorer pak an...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  positive  Berikan kesejahteraan buat guru honorer pak......   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  Berikan kesejahteraan buat guru honorer pak An...   \n",
       "\n",
       "                                        case_folding  \\\n",
       "0  paa bales dm pa saya mau nanya soal paket bela...   \n",
       "1  berikan kesejahteraan buat guru honorer pak an...   \n",
       "\n",
       "                                        tokenization  \\\n",
       "0  [paa, bales, dm, pa, saya, mau, nanya, soal, p...   \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...   \n",
       "\n",
       "                                       normalization  \n",
       "0  [paa, balas, dm, pa, saya, mau, bertanya, soal...  \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['normalization'] = dataset['tokenization'].apply(normalized_term)\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e3fa6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e48ace2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada', 'adalah', 'adanya', 'adapun', 'agak']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
    "# get stopword indonesia\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "list_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af36e69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------- Custom stopword  ------------------------------------\n",
    "# append additional stopword\n",
    "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo',\n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang',\n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih',\n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya',\n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't',\n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah', 'man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8669011f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenization</th>\n",
       "      <th>normalization</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>paa bales dm pa saya mau nanya soal paket bela...</td>\n",
       "      <td>[paa, bales, dm, pa, saya, mau, nanya, soal, p...</td>\n",
       "      <td>[paa, balas, dm, pa, saya, mau, bertanya, soal...</td>\n",
       "      <td>[paa, balas, dm, pa, paket, belajar, telkomsel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak......</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak An...</td>\n",
       "      <td>berikan kesejahteraan buat guru honorer pak an...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "      <td>[kesejahteraan, guru, honorer, angkat, pns, be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  positive  Berikan kesejahteraan buat guru honorer pak......   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  Berikan kesejahteraan buat guru honorer pak An...   \n",
       "\n",
       "                                        case_folding  \\\n",
       "0  paa bales dm pa saya mau nanya soal paket bela...   \n",
       "1  berikan kesejahteraan buat guru honorer pak an...   \n",
       "\n",
       "                                        tokenization  \\\n",
       "0  [paa, bales, dm, pa, saya, mau, nanya, soal, p...   \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...   \n",
       "\n",
       "                                       normalization  \\\n",
       "0  [paa, balas, dm, pa, saya, mau, bertanya, soal...   \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...   \n",
       "\n",
       "                                            stopword  \n",
       "0    [paa, balas, dm, pa, paket, belajar, telkomsel]  \n",
       "1  [kesejahteraan, guru, honorer, angkat, pns, be...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "dataset['stopword'] = dataset['normalization'].apply(stopwords_removal)\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab4188",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd26f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31df197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e566fdc04ea445d29f044509c757a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1451 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenization</th>\n",
       "      <th>normalization</th>\n",
       "      <th>stopword</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>Paa bales DM pa saya mau nanya soal paket bela...</td>\n",
       "      <td>paa bales dm pa saya mau nanya soal paket bela...</td>\n",
       "      <td>[paa, bales, dm, pa, saya, mau, nanya, soal, p...</td>\n",
       "      <td>[paa, balas, dm, pa, saya, mau, bertanya, soal...</td>\n",
       "      <td>[paa, balas, dm, pa, paket, belajar, telkomsel]</td>\n",
       "      <td>[paa, balas, dm, pa, paket, ajar, telkomsel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak......</td>\n",
       "      <td>Berikan kesejahteraan buat guru honorer pak An...</td>\n",
       "      <td>berikan kesejahteraan buat guru honorer pak an...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "      <td>[berikan, kesejahteraan, buat, guru, honorer, ...</td>\n",
       "      <td>[kesejahteraan, guru, honorer, angkat, pns, be...</td>\n",
       "      <td>[sejahtera, guru, honorer, angkat, pns, tahap,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Pak sekolah tatap muka pakðŸ˜ƒ</td>\n",
       "      <td>Pak sekolah tatap muka pak</td>\n",
       "      <td>pak sekolah tatap muka pak</td>\n",
       "      <td>[pak, sekolah, tatap, muka, pak]</td>\n",
       "      <td>[pak, sekolah, tatap, muka, pak]</td>\n",
       "      <td>[sekolah, tatap, muka]</td>\n",
       "      <td>[sekolah, tatap, muka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@putiageng25 cari beasiswa aja. Rajin2 cari in...</td>\n",
       "      <td>cari beasiswa aja Rajin cari info di website p...</td>\n",
       "      <td>cari beasiswa aja rajin cari info di website p...</td>\n",
       "      <td>[cari, beasiswa, aja, rajin, cari, info, di, w...</td>\n",
       "      <td>[cari, beasiswa, saja, rajin, cari, informasi,...</td>\n",
       "      <td>[cari, beasiswa, rajin, cari, informasi, situs...</td>\n",
       "      <td>[cari, beasiswa, rajin, cari, informasi, situs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@sahabathistoria capek2 kuliah tapi kerja sesu...</td>\n",
       "      <td>capek kuliah tapi kerja sesuai progessi gak di...</td>\n",
       "      <td>capek kuliah tapi kerja sesuai progessi gak di...</td>\n",
       "      <td>[capek, kuliah, tapi, kerja, sesuai, progessi,...</td>\n",
       "      <td>[capek, kuliah, tapi, kerja, sesuai, progessi,...</td>\n",
       "      <td>[capek, kuliah, kerja, sesuai, progessi, dihar...</td>\n",
       "      <td>[capek, kuliah, kerja, sesuai, progessi, harga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  \\\n",
       "0   neutral  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  positive  Berikan kesejahteraan buat guru honorer pak......   \n",
       "2   neutral                        Pak sekolah tatap muka pakðŸ˜ƒ   \n",
       "3   neutral  @putiageng25 cari beasiswa aja. Rajin2 cari in...   \n",
       "4  positive  @sahabathistoria capek2 kuliah tapi kerja sesu...   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0  Paa bales DM pa saya mau nanya soal paket bela...   \n",
       "1  Berikan kesejahteraan buat guru honorer pak An...   \n",
       "2                         Pak sekolah tatap muka pak   \n",
       "3  cari beasiswa aja Rajin cari info di website p...   \n",
       "4  capek kuliah tapi kerja sesuai progessi gak di...   \n",
       "\n",
       "                                        case_folding  \\\n",
       "0  paa bales dm pa saya mau nanya soal paket bela...   \n",
       "1  berikan kesejahteraan buat guru honorer pak an...   \n",
       "2                         pak sekolah tatap muka pak   \n",
       "3  cari beasiswa aja rajin cari info di website p...   \n",
       "4  capek kuliah tapi kerja sesuai progessi gak di...   \n",
       "\n",
       "                                        tokenization  \\\n",
       "0  [paa, bales, dm, pa, saya, mau, nanya, soal, p...   \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...   \n",
       "2                   [pak, sekolah, tatap, muka, pak]   \n",
       "3  [cari, beasiswa, aja, rajin, cari, info, di, w...   \n",
       "4  [capek, kuliah, tapi, kerja, sesuai, progessi,...   \n",
       "\n",
       "                                       normalization  \\\n",
       "0  [paa, balas, dm, pa, saya, mau, bertanya, soal...   \n",
       "1  [berikan, kesejahteraan, buat, guru, honorer, ...   \n",
       "2                   [pak, sekolah, tatap, muka, pak]   \n",
       "3  [cari, beasiswa, saja, rajin, cari, informasi,...   \n",
       "4  [capek, kuliah, tapi, kerja, sesuai, progessi,...   \n",
       "\n",
       "                                            stopword  \\\n",
       "0    [paa, balas, dm, pa, paket, belajar, telkomsel]   \n",
       "1  [kesejahteraan, guru, honorer, angkat, pns, be...   \n",
       "2                             [sekolah, tatap, muka]   \n",
       "3  [cari, beasiswa, rajin, cari, informasi, situs...   \n",
       "4  [capek, kuliah, kerja, sesuai, progessi, dihar...   \n",
       "\n",
       "                                             stemmed  \n",
       "0       [paa, balas, dm, pa, paket, ajar, telkomsel]  \n",
       "1  [sejahtera, guru, honorer, angkat, pns, tahap,...  \n",
       "2                             [sekolah, tatap, muka]  \n",
       "3  [cari, beasiswa, rajin, cari, informasi, situs...  \n",
       "4  [capek, kuliah, kerja, sesuai, progessi, harga...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stemmed_term(document):\n",
    "    return [stemmer.stem(term) for term in document]\n",
    "\n",
    "dataset['stemmed'] = dataset['stopword'].swifter.apply(get_stemmed_term)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051177f",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68b71e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansing_1 = pd.read_excel('assets/cleansing.xlsx').iloc[:, 1:]\n",
    "cleansing_1.lable = cleansing_1.lable.replace('nrgatif', 'negatif')\n",
    "cleansing_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d059fa2",
   "metadata": {},
   "source": [
    "**Drop nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4d2da9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508, 8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansing_1.dropna(inplace=True)\n",
    "cleansing_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0783cc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negatif    825\n",
       "netral     399\n",
       "positif    284\n",
       "Name: lable, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansing_1.lable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4a6d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns={'sentiment': 'lable'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11ec83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.lable = dataset.lable.replace('neutral', 'netral')\n",
    "dataset.lable = dataset.lable.replace('positive', 'positif')\n",
    "dataset.lable = dataset.lable.replace('negative', 'negatif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7190ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2959, 8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = pd.concat([dataset, cleansing_1], axis=0)\n",
    "df_join.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2a53f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2959, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.dropna(inplace=True)\n",
    "df_join.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8efa7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.drop_duplicates('content', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cb45cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ef31887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.to_excel('assets/cleansing_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1d18dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('assets/cleansing.json', 'w') as file:\n",
    "    json.dump(dataset.to_dict(orient='records'), file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06bab4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
